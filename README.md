# End-to-End Data Engineering Project

This project demonstrates a **complete data engineering pipeline**
from raw data ingestion to analytics-ready output using
industry best practices.

---

## ğŸ— Architecture

Public API  
â†’ Raw Data Layer (JSON)  
â†’ Transformation Layer  
â†’ Processed Data (Parquet)

---

## ğŸ§° Tech Stack
- Python
- Pandas
- Requests
- Parquet
- Data Lake Architecture (Raw / Processed)

---

## ğŸ“‚ Project Structure

end-to-end-data-engineering-project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/        # Immutable raw API data (JSON)
â”‚   â””â”€â”€ processed/  # Cleaned analytics-ready data (Parquet)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingest_api_data.py
â”‚   â””â”€â”€ transform_raw_data.py
â”œâ”€â”€ docs/
â””â”€â”€ README.md

---

## âš™ï¸ Pipeline Flow

### 1ï¸âƒ£ Data Ingestion
- Fetches data from a public API
- Stores timestamped raw JSON files
- Ensures immutability of raw data

Script:

---

### 2ï¸âƒ£ Data Transformation
- Reads latest raw JSON file
- Normalizes nested data
- Writes columnar Parquet output

Script:

---

## â–¶ï¸ How to Run

```bash
pip install -r requirements.txt
python src/ingest_api_data.py
python src/transform_raw_data.py

### Commit message:

Key Data Engineering Concepts Demonstrated

Data lake layering (raw â†’ processed)

Idempotent ingestion

Schema normalization

Columnar storage (Parquet)

Production-style project structure
\
